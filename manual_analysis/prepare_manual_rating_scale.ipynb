{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:33:41.155594Z",
     "start_time": "2025-06-23T10:33:41.153435Z"
    }
   },
   "cell_type": "code",
   "source": "import random",
   "id": "4a94145eee806860",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:35:31.914169Z",
     "start_time": "2025-06-23T10:35:31.910101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_files(\n",
    "        mask_file,\n",
    "        check_df,\n",
    "        t1t2_df,\n",
    "        identifier\n",
    "):\n",
    "    with open(os.path.join('preference_manual_scale', f'{identifier}_mask.json'), 'w') as f:\n",
    "        json.dump(mask_file, f, indent=4)\n",
    "    check_df.to_csv(os.path.join('preference_manual_scale', f'{identifier}_check_df.csv'), index=False)\n",
    "    t1t2_df.to_csv(os.path.join('preference_manual_scale', f'{identifier}_t1t2_df.csv'), index=False)"
   ],
   "id": "e95839a0ac311f07",
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T09:22:22.651477Z",
     "start_time": "2025-06-23T09:22:22.132773Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "CURRENT_FILE_DIR = os.getcwd()\n",
    "IMPROVED_DIR = '/home/thomas/PycharmProjects/protefra/projects/improvement_pipeline/improved_out'\n",
    "MICROTEXTS_PATH = os.path.join(IMPROVED_DIR, 'MICROTEXTS', 'llama3_nemotron_cleaned.json')\n",
    "with open(MICROTEXTS_PATH) as f:\n",
    "    microtext_data = json.load(f)\n",
    "\n",
    "ESSAYS_PATH = os.path.join(IMPROVED_DIR, 'ESSAYS', 'llama3_nemotron_cleaned.json')\n",
    "with open(ESSAYS_PATH) as f:\n",
    "    essay_data = json.load(f)\n",
    "\n",
    "REVISIONS1_PATH = os.path.join(IMPROVED_DIR, 'REVISIONS', 'llama3_nemotron_cleaned_revision1.json')\n",
    "with open(REVISIONS1_PATH) as f:\n",
    "    revision1_data = json.load(f)\n",
    "\n",
    "REVISIONS2_PATH = os.path.join(IMPROVED_DIR, 'REVISIONS', 'llama3_nemotron_cleaned_revision2.json')\n",
    "with open(REVISIONS2_PATH) as f:\n",
    "    revision2_data = json.load(f)\n",
    "\n",
    "REVISIONS3_PATH = os.path.join(IMPROVED_DIR, 'REVISIONS', 'llama3_nemotron_cleaned_revision3.json')\n",
    "with open(REVISIONS3_PATH) as f:\n",
    "    revision3_data = json.load(f)\n",
    "\n",
    "REVISIONS1_FEEDBACK_PATH = os.path.join(IMPROVED_DIR, 'REVISIONS_FEEDBACK', 'llama3_nemotron_cleaned_revision1.json')\n",
    "with open(REVISIONS1_FEEDBACK_PATH) as f:\n",
    "    revision1_feedback_data = json.load(f)\n",
    "\n",
    "REVISIONS2_FEEDBACK_PATH = os.path.join(IMPROVED_DIR, 'REVISIONS_FEEDBACK', 'llama3_nemotron_cleaned_revision2.json')\n",
    "with open(REVISIONS2_FEEDBACK_PATH) as f:\n",
    "    revision2_feedback_data = json.load(f)\n",
    "\n",
    "REVISIONS3_FEEDBACK_PATH = os.path.join(IMPROVED_DIR, 'REVISIONS_FEEDBACK', 'llama3_nemotron_cleaned_revision3.json')\n",
    "with open(REVISIONS3_FEEDBACK_PATH) as f:\n",
    "    revision3_feedback_data = json.load(f)\n",
    "\n",
    "data_all = [\n",
    "    microtext_data,\n",
    "    microtext_data,\n",
    "    essay_data,\n",
    "    revision1_data,\n",
    "    revision2_data,\n",
    "    revision3_data,\n",
    "    revision1_feedback_data,\n",
    "    revision2_feedback_data,\n",
    "    revision3_feedback_data\n",
    "]\n",
    "data_all_names = [\n",
    "    'microtext_de',\n",
    "    'microtext_en',\n",
    "    'essay',\n",
    "    'revision1',\n",
    "    'revision2',\n",
    "    'revision3',\n",
    "    'revision1_feedback',\n",
    "    'revision2_feedback',\n",
    "    'revision3_feedback'\n",
    "]\n",
    "\n",
    "microtext_english_ids = [\n",
    "    'micro_b011',\n",
    "    'micro_b055,',\n",
    "    'micro_b001',\n",
    "    'micro_b046',\n",
    "    'micro_b019',\n",
    "    'micro_b031',\n",
    "    'micro_b023',\n",
    "    'micro_b051',\n",
    "    'micro_b013',\n",
    "    'micro_k003'\n",
    "]\n",
    "microtext_german_ids = [\n",
    "    'micro_b011',\n",
    "    'micro_b055',\n",
    "    'micro_b001',\n",
    "    'micro_b046',\n",
    "    'micro_b019',\n",
    "    'micro_b031',\n",
    "    'micro_b023',\n",
    "    'micro_b051',\n",
    "    'micro_b013',\n",
    "    'micro_k003'\n",
    "]\n",
    "essays_ids = [\n",
    "    'essay226.txt',\n",
    "    'essay282.txt',\n",
    "    'essay085.txt',\n",
    "    'essay286.txt',\n",
    "    'essay095.txt',\n",
    "    'essay034.txt',\n",
    "    'essay127.txt',\n",
    "    'essay094.txt',\n",
    "    'essay212.txt',\n",
    "    'essay392.txt'\n",
    "]\n",
    "rev1_ids = [\n",
    "    'draft1_2018argrewrite_9.txt',\n",
    "    'draft1_2018argrewrite_16.txt',\n",
    "    'draft1_2018argrewrite_26.txt',\n",
    "    'draft1_2018argrewrite_65.txt',\n",
    "    'draft1_2018argrewrite_63.txt',\n",
    "    'draft1_2018argrewrite_46.txt',\n",
    "    'draft1_2018argrewrite_101.txt',\n",
    "    'draft1_2018argrewrite_103.txt',\n",
    "    'draft1_2018argrewrite_70.txt',\n",
    "    'draft1_2018argrewrite_19.txt'\n",
    "]\n",
    "rev2_ids = [\n",
    "    'draft1_2018argrewrite_9.txt',\n",
    "    'draft1_2018argrewrite_16.txt',\n",
    "    'draft1_2018argrewrite_26.txt',\n",
    "    'draft1_2018argrewrite_65.txt',\n",
    "    'draft1_2018argrewrite_63.txt',\n",
    "    'draft1_2018argrewrite_46.txt',\n",
    "    'draft1_2018argrewrite_101.txt',\n",
    "    'draft1_2018argrewrite_103.txt',\n",
    "    'draft1_2018argrewrite_70.txt',\n",
    "    'draft1_2018argrewrite_19.txt'\n",
    "]\n",
    "rev3_ids = [\n",
    "    'draft1_2018argrewrite_17.txt',\n",
    "    'draft1_2018argrewrite_11.txt',\n",
    "    'draft1_2018argrewrite_19.txt',\n",
    "    'draft1_2018argrewrite_74.txt',\n",
    "    'draft1_2018argrewrite_65.txt',\n",
    "    'draft1_2018argrewrite_78.txt',\n",
    "    'draft1_2018argrewrite_40.txt',\n",
    "    'draft1_2018argrewrite_101.txt',\n",
    "    'draft1_2018argrewrite_76.txt',\n",
    "    'draft1_2018argrewrite_38.txt'\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:41:04.394611Z",
     "start_time": "2025-06-23T09:41:04.210580Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "c990155268b0f3a0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:41:58.801318Z",
     "start_time": "2025-06-23T09:41:58.797665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "essay_t1t2_df = pd.read_csv('essay_t1t2_df.csv')\n",
    "graph_ids = essay_t1t2_df['graph_id'].tolist()\n",
    "essays_ids.extend(graph_ids)"
   ],
   "id": "adce846202bde7c5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:42:50.941534Z",
     "start_time": "2025-06-23T09:42:50.936606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "microtext_de_t1t2_df = pd.read_csv('microtext_de_t1t2_df.csv')\n",
    "graph_ids = microtext_de_t1t2_df['graph_id'].tolist()\n",
    "microtext_german_ids.extend(graph_ids)"
   ],
   "id": "def4d0bf9b6e1a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:43:03.143305Z",
     "start_time": "2025-06-23T09:43:03.139022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "microtext_en_t1t2_df = pd.read_csv('microtext_en_t1t2_df.csv')\n",
    "graph_ids = microtext_en_t1t2_df['graph_id'].tolist()\n",
    "microtext_english_ids.extend(graph_ids)"
   ],
   "id": "aa0d4a1acc1dd814",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:43:26.773154Z",
     "start_time": "2025-06-23T09:43:26.767753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "revision1_t1t2_df = pd.read_csv('revision1_t1t2_df.csv')\n",
    "graph_ids = revision1_t1t2_df['graph_id'].tolist()\n",
    "rev1_ids.extend(graph_ids)"
   ],
   "id": "17e0d53d6708857e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:43:32.647182Z",
     "start_time": "2025-06-23T09:43:32.641314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "revision2_t1t2_df = pd.read_csv('revision2_t1t2_df.csv')\n",
    "graph_ids = revision2_t1t2_df['graph_id'].tolist()\n",
    "rev2_ids.extend(graph_ids)"
   ],
   "id": "59258ed8b929e4d1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:43:40.051868Z",
     "start_time": "2025-06-23T09:43:40.045853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "revision3_t1t2_df = pd.read_csv('revision3_t1t2_df.csv')\n",
    "graph_ids = revision3_t1t2_df['graph_id'].tolist()\n",
    "rev3_ids.extend(graph_ids)"
   ],
   "id": "868baca4da6cf58",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:17:53.820251Z",
     "start_time": "2025-06-23T10:17:53.780800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out = []\n",
    "\n",
    "for data, data_name in zip(data_all, data_all_names):\n",
    "    for approach_data in data:\n",
    "        original_arguments = approach_data['original_arguments']\n",
    "        improved_arguments = approach_data['improved_arguments']\n",
    "        graph_ids = approach_data['graph_id']\n",
    "        topic_ids = approach_data['topic_id']\n",
    "        tmp_df = pd.DataFrame({\n",
    "            'original_arguments': original_arguments,\n",
    "            'improved_arguments': improved_arguments,\n",
    "            'graph_id': graph_ids,\n",
    "            'topic_id': topic_ids,\n",
    "            'approach': [approach_data['approach']] * len(original_arguments),\n",
    "            'dataset_name': [data_name] * len(original_arguments),\n",
    "        })\n",
    "        # remove @ from end of improved_arguments if its at the very end\n",
    "        tmp_df['improved_arguments'] = tmp_df['improved_arguments'].str.rstrip('@')\n",
    "\n",
    "        if data_name == 'microtext_de':\n",
    "            tmp_df = tmp_df[tmp_df['topic_id'].str.endswith('(de)')]\n",
    "        elif data_name == 'microtext_en':\n",
    "            tmp_df = tmp_df[tmp_df['topic_id'].str.endswith('(en)')]\n",
    "\n",
    "        # filter out those where graph id is in the list of ids\n",
    "        if data_name == 'microtext_en':\n",
    "            tmp_df = tmp_df[~tmp_df['graph_id'].isin(microtext_english_ids)]\n",
    "        elif data_name == 'microtext_de':\n",
    "            tmp_df = tmp_df[~tmp_df['graph_id'].isin(microtext_german_ids)]\n",
    "        elif data_name == 'essay':\n",
    "            tmp_df = tmp_df[~tmp_df['graph_id'].isin(essays_ids)]\n",
    "        elif data_name == 'revision1':\n",
    "            tmp_df = tmp_df[~tmp_df['graph_id'].isin(rev1_ids)]\n",
    "        elif data_name == 'revision2':\n",
    "            tmp_df = tmp_df[~tmp_df['graph_id'].isin(rev2_ids)]\n",
    "        elif data_name == 'revision3':\n",
    "            tmp_df = tmp_df[~tmp_df['graph_id'].isin(rev3_ids)]\n",
    "        elif data_name == 'revision1_feedback':\n",
    "            tmp_df = tmp_df[~tmp_df['graph_id'].isin(rev1_ids)]\n",
    "        elif data_name == 'revision2_feedback':\n",
    "            tmp_df = tmp_df[~tmp_df['graph_id'].isin(rev2_ids)]\n",
    "        elif data_name == 'revision3_feedback':\n",
    "            tmp_df = tmp_df[~tmp_df['graph_id'].isin(rev3_ids)]\n",
    "\n",
    "        # pick 10 for each dataset\n",
    "        samples = tmp_df.sample(10, random_state=42)\n",
    "        out.append(samples)"
   ],
   "id": "c3f449fe3f8763ca",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:17:54.348650Z",
     "start_time": "2025-06-23T10:17:54.344599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_df = pd.concat(out, ignore_index=True)\n",
    "out_df = out_df.sort_values(by=['approach', 'dataset_name'])"
   ],
   "id": "b82538b1d38dc9f4",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "out_df = out_df[(out_df['approach'] == 'direct') & (out_df['dataset_name'].isin(['essay', 'microtext_de', 'microtext_en', 'revision1', 'revision2', 'revision3']))]\n",
    "out_df"
   ],
   "id": "8b8d8b85587796ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:36:22.264245Z",
     "start_time": "2025-06-23T10:36:22.257086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "microtexts_english = out_df[out_df['dataset_name'] == 'microtext_en']\n",
    "check_mt_english = microtexts_english[microtexts_english['approach'] == 'direct']\n",
    "\n",
    "# create boolean of len(check_mt_english), randomly\n",
    "check_mt_english_mask = random.choices([True, False], k=len(check_mt_english))\n",
    "\n",
    "# add columns text1 and text2 - use original_arguments for text1 of mask is True, else improved_arguments\n",
    "check_mt_english['text1'] = check_mt_english['original_arguments'].where(check_mt_english_mask,\n",
    "                                                                         check_mt_english['improved_arguments'])\n",
    "check_mt_english['text2'] = check_mt_english['improved_arguments'].where(check_mt_english_mask,\n",
    "                                                                         check_mt_english['original_arguments'])\n",
    "t1t2_mt_english = check_mt_english[['topic_id', 'graph_id', 'text1', 'text2']].copy()\n",
    "save_files(check_mt_english_mask, check_mt_english, t1t2_mt_english, 'microtext_en')"
   ],
   "id": "6c4039a6988ac4d4",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:36:23.157450Z",
     "start_time": "2025-06-23T10:36:23.151370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "microtexts_german = out_df[out_df['dataset_name'] == 'microtext_de']\n",
    "check_mt_german = microtexts_german[microtexts_german['approach'] == 'direct']\n",
    "# create boolean of len(check_mt_german), randomly\n",
    "check_mt_german_mask = random.choices([True, False], k=len(check_mt_german))\n",
    "# add columns text1 and text2 - use original_arguments for text1 of mask is True, else improved_arguments\n",
    "check_mt_german['text1'] = check_mt_german['original_arguments'].where(check_mt_german_mask,\n",
    "                                                                       check_mt_german['improved_arguments'])\n",
    "check_mt_german['text2'] = check_mt_german['improved_arguments'].where(check_mt_german_mask,\n",
    "                                                                       check_mt_german['original_arguments'])\n",
    "t1t2_mt_german = check_mt_german[['topic_id', 'graph_id', 'text1', 'text2']].copy()\n",
    "save_files(check_mt_german_mask, check_mt_german, t1t2_mt_german, 'microtext_de')"
   ],
   "id": "b43c84e492f857f3",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:36:23.591057Z",
     "start_time": "2025-06-23T10:36:23.582689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "essays = out_df[out_df['dataset_name'] == 'essay']\n",
    "check_essays = essays[essays['approach'] == 'direct']\n",
    "# create boolean of len(check_essays), randomly\n",
    "check_essays_mask = random.choices([True, False], k=len(check_essays))\n",
    "# add columns text1 and text2 - use original_arguments for text1 of mask is True, else improved_arguments\n",
    "check_essays['text1'] = check_essays['original_arguments'].where(check_essays_mask,\n",
    "                                                                 check_essays['improved_arguments'])\n",
    "check_essays['text2'] = check_essays['improved_arguments'].where(check_essays_mask,\n",
    "                                                                 check_essays['original_arguments'])\n",
    "t1t2_essays = check_essays[['topic_id', 'graph_id', 'text1', 'text2']].copy()\n",
    "save_files(check_essays_mask, check_essays, t1t2_essays, 'essay')"
   ],
   "id": "58163b8f8046cdee",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:36:23.969425Z",
     "start_time": "2025-06-23T10:36:23.962292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "revisions1 = out_df[out_df['dataset_name'] == 'revision1']\n",
    "check_revisions1 = revisions1[revisions1['approach'] == 'direct']\n",
    "# create boolean of len(check_revisions1), randomly\n",
    "check_revisions1_mask = random.choices([True, False], k=len(check_revisions1))\n",
    "# add columns text1 and text2 - use original_arguments for text1 of mask is True, else improved_arguments\n",
    "check_revisions1['text1'] = check_revisions1['original_arguments'].where(check_revisions1_mask,\n",
    "                                                                         check_revisions1['improved_arguments'])\n",
    "check_revisions1['text2'] = check_revisions1['improved_arguments'].where(check_revisions1_mask,\n",
    "                                                                         check_revisions1['original_arguments'])\n",
    "t1t2_revisions1 = check_revisions1[['topic_id', 'graph_id', 'text1', 'text2']].copy()\n",
    "save_files(check_revisions1_mask, check_revisions1, t1t2_revisions1, 'revision1')"
   ],
   "id": "674f285b1cdec60d",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:36:24.320742Z",
     "start_time": "2025-06-23T10:36:24.313932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "revisions2 = out_df[out_df['dataset_name'] == 'revision2']\n",
    "check_revisions2 = revisions2[revisions2['approach'] == 'direct']\n",
    "# create boolean of len(check_revisions2), randomly\n",
    "check_revisions2_mask = random.choices([True, False], k=len(check_revisions2))\n",
    "# add columns text1 and text2 - use original_arguments for text1 of mask is True, else improved_arguments\n",
    "check_revisions2['text1'] = check_revisions2['original_arguments'].where(check_revisions2_mask,\n",
    "                                                                         check_revisions2['improved_arguments'])\n",
    "check_revisions2['text2'] = check_revisions2['improved_arguments'].where(check_revisions2_mask,\n",
    "                                                                         check_revisions2['original_arguments'])\n",
    "t1t2_revisions2 = check_revisions2[['topic_id', 'graph_id', 'text1', 'text2']].copy()\n",
    "save_files(check_revisions2_mask, check_revisions2, t1t2_revisions2, 'revision2')"
   ],
   "id": "1e727d4bd72c9d10",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T10:36:27.665296Z",
     "start_time": "2025-06-23T10:36:27.656882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "revisions3 = out_df[out_df['dataset_name'] == 'revision3']\n",
    "check_revisions3 = revisions3[revisions3['approach'] == 'direct']\n",
    "# create boolean of len(check_revisions3), randomly\n",
    "check_revisions3_mask = random.choices([True, False], k=len(check_revisions3))\n",
    "# add columns text1 and text2 - use original_arguments for text1 of mask is True, else improved_arguments\n",
    "check_revisions3['text1'] = check_revisions3['original_arguments'].where(check_revisions3_mask,\n",
    "                                                                         check_revisions3['improved_arguments'])\n",
    "check_revisions3['text2'] = check_revisions3['improved_arguments'].where(check_revisions3_mask,\n",
    "                                                                         check_revisions3['original_arguments'])\n",
    "t1t2_revisions3 = check_revisions3[['topic_id', 'graph_id', 'text1', 'text2']].copy()\n",
    "save_files(check_revisions3_mask, check_revisions3, t1t2_revisions3, 'revision3')"
   ],
   "id": "b521f4c9cf3b6d55",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18e6662f707a6207"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
